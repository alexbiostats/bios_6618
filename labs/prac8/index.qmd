---
title: "Week 8 Practice Problems"
author: 
  name: Alex Kaizer
  roles: "Instructor"
  affiliation: University of Colorado-Anschutz Medical Campus
toc: true
toc_float: true
toc-location: left
format:
  html:
    code-fold: show
    code-overflow: wrap 
    code-tools: true
---

```{r, echo=F, message=F, warning=F}
library(kableExtra)
library(dplyr)
```

This page includes optional practice problems, many of which are structured to assist you on the homework with [Solutions provided on a separate page](/labs/prac8s/index.qmd). Data sets, if needed, are provided on the BIOS 6618 Canvas page for students registered for the course.

This week's extra practice exercises are focusing on examining the diagnostic plots for various regression models simulated to violate various regression assumptions. The interpretation of models with transformations are also explored for further practice.

# Exercise 1: Diagnostic Examination

For each of the following sets of plots, identify which, if any, assumptions may be violated for the simple linear regression model.

## 1a. Scenario 1

```{r, echo=F}
# Code to generate figures for violation of linearity
set.seed(303)
x <- rnorm(n=100, mean=10, sd=3) # simulate a single continuous predictor with mean=10 and SD=3
reg <- 15 + 5 * x - 1 * x^2 - 0.25 * x^3 # set the regression equation so the intercept=10 and the slope=3
y <- rnorm(n=100, mean=reg, sd=8) # simulate the outcome based on the conditional mean

mod1 <- glm(y ~ x)

par(mfrow=c(2,2), mar=c(4.1,4.1,3.1,2.1))
plot(x=x, y=y, xlab='X', ylab='Y', main='Scatterplot', cex=0.7); abline( mod1 )

plot(x=x, y=rstudent(mod1), xlab='X', ylab='Jackknife Residual', 
     main='Residual Plot', cex=0.7); abline(h=0, lty=2, col='gray65')

hist(rstudent(mod1), xlab='Jackknife Residual', 
     main='Histogram of Residuals', freq=F, breaks=seq(-6,1,0.25)); 
  curve( dnorm(x,mean=0,sd=1), lwd=2, col='blue', add=T)

plot( ppoints(length(rstudent(mod1))), sort(pnorm(rstudent(mod1))), 
      xlab='Observed Cumulative Probability', 
      ylab='Expected Cumulative Probability', 
      main='Normal Probability Plot', cex=0.7); 
  abline(a=0,b=1, col='gray65', lwd=1)
```

## 1b. Scenario 2

```{r, echo=F}
# Code to generate figures for violation of normality
set.seed(515)
x <- rnorm(n=100, mean=10, sd=3) # simulate a single continuous predictor with mean=10 and SD=3
reg <- 15 + 5 * x # set the regression equation so the intercept=10 and the slope=3
y <- rexp(n=100, rate=1/reg) # simulate the outcome based on the conditional mean

mod1 <- glm(y ~ x)

par(mfrow=c(2,2), mar=c(4.1,4.1,3.1,2.1))
plot(x=x, y=y, xlab='X', ylab='Y', main='Scatterplot', cex=0.7); abline( mod1 )

plot(x=x, y=rstudent(mod1), xlab='X', ylab='Jackknife Residual', 
     main='Residual Plot', cex=0.7); abline(h=0, lty=2, col='gray65')

hist(rstudent(mod1), xlab='Jackknife Residual', 
     main='Histogram of Residuals', freq=F, breaks=seq(-4,7,0.25)); 
  curve( dnorm(x,mean=0,sd=1), lwd=2, col='blue', add=T)

plot( ppoints(length(rstudent(mod1))), sort(pnorm(rstudent(mod1))), 
      xlab='Observed Cumulative Probability', 
      ylab='Expected Cumulative Probability', 
      main='Normal Probability Plot', cex=0.7); 
  abline(a=0,b=1, col='gray65', lwd=1)
```

## 1c. Scenario 3

```{r, echo=F}
# Code to generate figures for no violations
set.seed(720)
x <- rnorm(n=100, mean=10, sd=3) # simulate a single continuous predictor with mean=10 and SD=3
reg <- 15 + 5 * x  # set the regression equation so the intercept=10 and the slope=3
y <- rnorm(n=100, mean=reg, sd=8) # simulate the outcome based on the conditional mean

mod1 <- glm(y ~ x)

par(mfrow=c(2,2), mar=c(4.1,4.1,3.1,2.1))
plot(x=x, y=y, xlab='X', ylab='Y', main='Scatterplot', cex=0.7); abline( mod1 )

plot(x=x, y=rstudent(mod1), xlab='X', ylab='Jackknife Residual', 
     main='Residual Plot', cex=0.7); abline(h=0, lty=2, col='gray65')

hist(rstudent(mod1), xlab='Jackknife Residual', 
     main='Histogram of Residuals', freq=F, breaks=seq(-4,4,0.25)); 
  curve( dnorm(x,mean=0,sd=1), lwd=2, col='blue', add=T)

plot( ppoints(length(rstudent(mod1))), sort(pnorm(rstudent(mod1))), 
      xlab='Observed Cumulative Probability', 
      ylab='Expected Cumulative Probability', 
      main='Normal Probability Plot', cex=0.7); 
  abline(a=0,b=1, col='gray65', lwd=1)
```

## 1d. Scenario 4

```{r, echo=F}
# Code to generate figures for violation of homoscedasticity
set.seed(660)
x <- rnorm(n=100, mean=10, sd=3) # simulate a single continuous predictor with mean=10 and SD=3
reg <- 15 + 5 * x  # set the regression equation so the intercept=10 and the slope=3
y <- rnorm(n=100, mean=reg, sd=x^2) # simulate the outcome based on the conditional mean

mod1 <- glm(y ~ x)

par(mfrow=c(2,2), mar=c(4.1,4.1,3.1,2.1))
plot(x=x, y=y, xlab='X', ylab='Y', main='Scatterplot', cex=0.7); abline( mod1 )

plot(x=x, y=rstudent(mod1), xlab='X', ylab='Jackknife Residual', 
     main='Residual Plot', cex=0.7); abline(h=0, lty=2, col='gray65')

hist(rstudent(mod1), xlab='Jackknife Residual', 
     main='Histogram of Residuals', freq=F, breaks=seq(-6,4,0.25)); 
  curve( dnorm(x,mean=0,sd=1), lwd=2, col='blue', add=T)

plot( ppoints(length(rstudent(mod1))), sort(pnorm(rstudent(mod1))), 
      xlab='Observed Cumulative Probability', 
      ylab='Expected Cumulative Probability', 
      main='Normal Probability Plot', cex=0.7); 
  abline(a=0,b=1, col='gray65', lwd=1)
```

## 1e. Scenario 5

```{r, echo=F}
# Code to generate figures for violation of homoscedasticity, linearity, and normality
set.seed(660)
x <- rnorm(n=100, mean=10, sd=3) # simulate a single continuous predictor with mean=10 and SD=3
reg <- 15 + 5 * x + 0.5 * x^2  # set the regression equation so the intercept=10 and the slope=3
y <- rgamma(n=100, shape=reg, scale=x^2) # simulate the outcome based on the conditional mean

mod1 <- glm(y ~ x)

par(mfrow=c(2,2), mar=c(4.1,4.1,3.1,2.1))
plot(x=x, y=y, xlab='X', ylab='Y', main='Scatterplot', cex=0.7); abline( mod1 )

plot(x=x, y=rstudent(mod1), xlab='X', ylab='Jackknife Residual', 
     main='Residual Plot', cex=0.7); abline(h=0, lty=2, col='gray65')

hist(rstudent(mod1), xlab='Jackknife Residual', 
     main='Histogram of Residuals', freq=F, breaks=seq(-2,7,0.25)); 
  curve( dnorm(x,mean=0,sd=1), lwd=2, col='blue', add=T)

plot( ppoints(length(rstudent(mod1))), sort(pnorm(rstudent(mod1))), 
      xlab='Observed Cumulative Probability', 
      ylab='Expected Cumulative Probability', 
      main='Normal Probability Plot', cex=0.7); 
  abline(a=0,b=1, col='gray65', lwd=1)
```


# Exercise 2: Data Transformation Interpretations

We will use the blood storage dataset from our course site:

```{r}
dat <- read.csv('../../.data/Blood_Storage.csv')
```

The dataset includes 316 men who had undergone radical prostatectomy and received transfusion during or within 30 days of the surgical procedure and had available PSA follow-up data . 

For each of the following models, what are the estimates of the intercept and slope and how would you interpret them? If possible, for transformations of the dependent variable, $Y$, also transform the estimate of your slope and its 95% confidence interval back to its non-transformed scale and interpret.

## 2a. $Y$, $X$

```{r}
summary(lm(PVol ~ Age, data=dat))
```


## 2b. $log(Y)$, $X$

```{r}
summary(lm(log(PVol) ~ Age, data=dat))
```


## 2c. $\sqrt{Y}$, $X$

```{r}
summary(lm(sqrt(PVol) ~ Age, data=dat))
```


## 2d. $Y$, $log(X)$

```{r}
summary(lm(PVol ~ log(Age), data=dat))
```


## 2e. $log(Y)$, $log(X)$

```{r}
summary(lm(log(PVol) ~ log(Age), data=dat))
```



